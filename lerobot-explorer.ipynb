{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e40af32-6c2d-4c11-bfff-0cf7b37b4fc3",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e557aa0-d2af-4706-ab56-a92dce8cc0f9",
   "metadata": {},
   "source": [
    "## Data Layout Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6ded10-dd25-417f-80dd-6ae7a49897ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_ROOT = Path(\"/Users/nanzhu/code/Isaac-GR00T/demo_data/cube_to_bowl_5\")\n",
    "CHUNK_GLOB = \"chunk-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396fc2f0-bc08-4aed-8148-ce431cfa4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ DATASET ROOT\n",
      "  ‚Ä¢ Path: /Users/nanzhu/code/Isaac-GR00T/demo_data/cube_to_bowl_5\n",
      "\n",
      "üß© CHUNKS (data/video shards)\n",
      "  ‚Ä¢ Found 1 chunks:\n",
      "    - chunk-000\n",
      "\n",
      "üéûÔ∏è EPISODES (from parquet files)\n",
      "  ‚Ä¢ Total episodes discovered: 5\n",
      "  ‚Ä¢ Episode index preview: [0, 1, 2, 3, 4]\n",
      "\n",
      "üìπ VIDEO KEYS (camera / image modalities)\n",
      "  ‚Ä¢ Total video keys (cameras): 2\n",
      "  ‚Ä¢ Video key preview: ['observation.images.front', 'observation.images.wrist']\n",
      "\n",
      "üìÅ META FILES\n",
      "  ‚Ä¢ Meta files found: ['episodes.jsonl', 'info.json', 'modality.json', 'relative_stats.json', 'stats.json', 'tasks.jsonl']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textwrap import indent\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "@dataclass\n",
    "class DatasetLayout:\n",
    "    root: Path\n",
    "    meta_dir: Path\n",
    "    data_dir: Path\n",
    "    videos_dir: Path\n",
    "    chunks: List[str]\n",
    "\n",
    "    # episodes\n",
    "    parquet_files: List[Path]\n",
    "    episode_indices: List[int]\n",
    "    episode_to_parquet: Dict[int, Path]\n",
    "\n",
    "    # cameras / video keys\n",
    "    video_keys: List[str]\n",
    "    # mapping: video_key -> list of mp4 files\n",
    "    video_files: Dict[str, List[Path]]\n",
    "\n",
    "    # meta files\n",
    "    meta_files: Dict[str, Path]  # filename -> path\n",
    "\n",
    "def _parse_episode_index(p: Path) -> Optional[int]:\n",
    "    # episode_000123.parquet or episode_000123.mp4\n",
    "    m = re.search(r\"episode_(\\d+)\\.(parquet|mp4)$\", p.name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def discover_layout(root: Path, chunk_glob: str = \"chunk-*\") -> DatasetLayout:\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"DATA_ROOT not found: {root}\")\n",
    "\n",
    "    meta_dir = root / \"meta\"\n",
    "    data_dir = root / \"data\"\n",
    "    videos_dir = root / \"videos\"\n",
    "\n",
    "    # chunks: union from data/chunk-* and videos/chunk-*\n",
    "    data_chunks = sorted([p.name for p in data_dir.glob(chunk_glob) if p.is_dir()]) if data_dir.exists() else []\n",
    "    video_chunks = sorted([p.name for p in videos_dir.glob(chunk_glob) if p.is_dir()]) if videos_dir.exists() else []\n",
    "    chunks = sorted(set(data_chunks + video_chunks))\n",
    "\n",
    "    # parquet files across chunks\n",
    "    parquet_files = []\n",
    "    for ch in chunks:\n",
    "        parquet_files.extend(sorted((data_dir / ch).glob(\"episode_*.parquet\")))\n",
    "    parquet_files = sorted(parquet_files)\n",
    "\n",
    "    episode_indices = []\n",
    "    episode_to_parquet = {}\n",
    "    for pq in parquet_files:\n",
    "        ei = _parse_episode_index(pq)\n",
    "        if ei is None:\n",
    "            continue\n",
    "        episode_indices.append(ei)\n",
    "        episode_to_parquet[ei] = pq\n",
    "    episode_indices = sorted(set(episode_indices))\n",
    "\n",
    "    # discover video keys: videos/chunk-xxx/<video_key>/episode_*.mp4\n",
    "    video_keys = []\n",
    "    video_files: Dict[str, List[Path]] = {}\n",
    "    for ch in chunks:\n",
    "        ch_dir = videos_dir / ch\n",
    "        if not ch_dir.exists():\n",
    "            continue\n",
    "        for vk_dir in sorted([p for p in ch_dir.iterdir() if p.is_dir()]):\n",
    "            vk = vk_dir.name\n",
    "            video_keys.append(vk)\n",
    "            video_files.setdefault(vk, [])\n",
    "            video_files[vk].extend(sorted(vk_dir.glob(\"episode_*.mp4\")))\n",
    "\n",
    "    video_keys = sorted(set(video_keys))\n",
    "    for vk in video_keys:\n",
    "        video_files[vk] = sorted(video_files.get(vk, []))\n",
    "\n",
    "    # meta files\n",
    "    meta_files = {}\n",
    "    if meta_dir.exists():\n",
    "        for p in sorted(meta_dir.iterdir()):\n",
    "            if p.is_file():\n",
    "                meta_files[p.name] = p\n",
    "\n",
    "    return DatasetLayout(\n",
    "        root=root,\n",
    "        meta_dir=meta_dir,\n",
    "        data_dir=data_dir,\n",
    "        videos_dir=videos_dir,\n",
    "        chunks=chunks,\n",
    "        parquet_files=parquet_files,\n",
    "        episode_indices=episode_indices,\n",
    "        episode_to_parquet=episode_to_parquet,\n",
    "        video_keys=video_keys,\n",
    "        video_files=video_files,\n",
    "        meta_files=meta_files,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def pretty_layout_summary(layout: DatasetLayout, preview_n: int = 5):\n",
    "    lines = []\n",
    "\n",
    "    lines.append(\"üì¶ DATASET ROOT\")\n",
    "    lines.append(f\"  ‚Ä¢ Path: {layout.root}\")\n",
    "\n",
    "    lines.append(\"\\nüß© CHUNKS (data/video shards)\")\n",
    "    if layout.chunks:\n",
    "        lines.append(f\"  ‚Ä¢ Found {len(layout.chunks)} chunks:\")\n",
    "        for ch in layout.chunks:\n",
    "            lines.append(f\"    - {ch}\")\n",
    "    else:\n",
    "        lines.append(\"  ‚ö†Ô∏è No chunks found\")\n",
    "\n",
    "    lines.append(\"\\nüéûÔ∏è EPISODES (from parquet files)\")\n",
    "    lines.append(f\"  ‚Ä¢ Total episodes discovered: {len(layout.episode_indices)}\")\n",
    "    if layout.episode_indices:\n",
    "        preview = layout.episode_indices[:preview_n]\n",
    "        lines.append(f\"  ‚Ä¢ Episode index preview: {preview}\"\n",
    "                     + (\"\" if len(layout.episode_indices) <= preview_n else \" ...\"))\n",
    "\n",
    "    lines.append(\"\\nüìπ VIDEO KEYS (camera / image modalities)\")\n",
    "    lines.append(f\"  ‚Ä¢ Total video keys (cameras): {len(layout.video_keys)}\")\n",
    "    if layout.video_keys:\n",
    "        preview = layout.video_keys[:preview_n]\n",
    "        lines.append(f\"  ‚Ä¢ Video key preview: {preview}\"\n",
    "                     + (\"\" if len(layout.video_keys) <= preview_n else \" ...\"))\n",
    "\n",
    "    lines.append(\"\\nüìÅ META FILES\")\n",
    "    if layout.meta_files:\n",
    "        lines.append(f\"  ‚Ä¢ Meta files found: {list(layout.meta_files.keys())}\")\n",
    "    else:\n",
    "        lines.append(\"  ‚ö†Ô∏è No meta files found\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "layout = discover_layout(DATA_ROOT, CHUNK_GLOB)\n",
    "print(pretty_layout_summary(layout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19285e3-01d6-43bd-bb2a-02783bd021fe",
   "metadata": {},
   "source": [
    "## Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab104290-3e87-4550-bb1e-5cf6411c8f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': '/Users/nanzhu/code/Isaac-GR00T/demo_data/cube_to_bowl_5',\n",
       " 'chunks': ['chunk-000'],\n",
       " 'num_parquet_files': 5,\n",
       " 'num_episodes_found': 5,\n",
       " 'video_keys': ['observation.images.front', 'observation.images.wrist'],\n",
       " 'num_video_keys': 2,\n",
       " 'meta_files': ['episodes.jsonl',\n",
       "  'info.json',\n",
       "  'modality.json',\n",
       "  'relative_stats.json',\n",
       "  'stats.json',\n",
       "  'tasks.jsonl'],\n",
       " 'codebase_version': 'v2.1',\n",
       " 'robot_type': 'so101_follower',\n",
       " 'total_episodes(meta)': 5,\n",
       " 'total_frames(meta)': 4148,\n",
       " 'fps(meta)': 30,\n",
       " 'total_videos(meta)': 10,\n",
       " 'data_path_template': 'data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet',\n",
       " 'video_path_template': 'videos/chunk-{episode_chunk:03d}/{video_key}/episode_{episode_index:06d}.mp4',\n",
       " 'num_features(meta)': 9,\n",
       " 'feature_keys(meta)': ['action',\n",
       "  'episode_index',\n",
       "  'frame_index',\n",
       "  'index',\n",
       "  'observation.images.front',\n",
       "  'observation.images.wrist',\n",
       "  'observation.state',\n",
       "  'task_index',\n",
       "  'timestamp']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_json(path: Path) -> dict:\n",
    "    return json.loads(path.read_text())\n",
    "\n",
    "info = None\n",
    "info_path = layout.meta_files.get(\"info.json\")\n",
    "if info_path and info_path.exists():\n",
    "    info = read_json(info_path)\n",
    "\n",
    "summary = {\n",
    "    \"root\": str(layout.root),\n",
    "    \"chunks\": layout.chunks,\n",
    "    \"num_parquet_files\": len(layout.parquet_files),\n",
    "    \"num_episodes_found\": len(layout.episode_indices),\n",
    "    \"video_keys\": layout.video_keys,\n",
    "    \"num_video_keys\": len(layout.video_keys),\n",
    "    \"meta_files\": sorted(layout.meta_files.keys()),\n",
    "}\n",
    "\n",
    "# enrich from info.json if present\n",
    "if info is not None:\n",
    "    summary.update({\n",
    "        \"codebase_version\": info.get(\"codebase_version\"),\n",
    "        \"robot_type\": info.get(\"robot_type\"),\n",
    "        \"total_episodes(meta)\": info.get(\"total_episodes\"),\n",
    "        \"total_frames(meta)\": info.get(\"total_frames\"),\n",
    "        \"fps(meta)\": info.get(\"fps\"),\n",
    "        \"total_videos(meta)\": info.get(\"total_videos\"),\n",
    "        \"data_path_template\": info.get(\"data_path\"),\n",
    "        \"video_path_template\": info.get(\"video_path\"),\n",
    "        \"num_features(meta)\": len(info.get(\"features\", {})),\n",
    "        \"feature_keys(meta)\": sorted(list(info.get(\"features\", {}).keys()))[:20],\n",
    "    })\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f5470e-3272-4470-943d-aacbe8af63de",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d93634cf-1978-4dbf-b29e-3bbf10eccaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layout validated.\n",
      "\n",
      "SUMMARY:\n",
      "  ‚Ä¢ root: /Users/nanzhu/code/Isaac-GR00T/demo_data/cube_to_bowl_5\n",
      "  ‚Ä¢ chunks: ['chunk-000']\n",
      "  ‚Ä¢ episodes_found: 5\n",
      "  ‚Ä¢ parquet_files_found: 5\n",
      "  ‚Ä¢ video_keys_found: 2\n",
      "  ‚Ä¢ videos_found_total: 10\n",
      "  ‚Ä¢ meta_files_found: ['episodes.jsonl', 'info.json', 'modality.json', 'relative_stats.json', 'stats.json', 'tasks.jsonl']\n",
      "\n",
      "COVERAGE (per key):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_type</th>\n",
       "      <th>key_name</th>\n",
       "      <th>episodes_present</th>\n",
       "      <th>episodes_missing</th>\n",
       "      <th>coverage_ratio</th>\n",
       "      <th>missing_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parquet</td>\n",
       "      <td>data</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video</td>\n",
       "      <td>observation.images.front</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video</td>\n",
       "      <td>observation.images.wrist</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key_type                  key_name  episodes_present  episodes_missing  \\\n",
       "0  parquet                      data                 5                 0   \n",
       "1    video  observation.images.front                 5                 0   \n",
       "2    video  observation.images.wrist                 5                 0   \n",
       "\n",
       "   coverage_ratio missing_examples  \n",
       "0             1.0               []  \n",
       "1             1.0               []  \n",
       "2             1.0               []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO.JSON COUNT CHECK:\n",
      "  ‚Ä¢ info.total_episodes: 5\n",
      "  ‚Ä¢ info.total_videos: 10\n",
      "  ‚Ä¢ episodes_found: 5\n",
      "  ‚Ä¢ videos_found_total: 10\n",
      "  ‚Ä¢ match_total_episodes: True\n",
      "  ‚Ä¢ match_total_videos: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def episode_coverage_report(layout: DatasetLayout) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a table:\n",
    "      key_type | key_name | episodes_present | episodes_missing | coverage_ratio\n",
    "    key_type includes: parquet, video\n",
    "    \"\"\"\n",
    "    all_eps = set(layout.episode_indices)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Parquet coverage (baseline)\n",
    "    parquet_eps = set(layout.episode_to_parquet.keys())\n",
    "    rows.append({\n",
    "        \"key_type\": \"parquet\",\n",
    "        \"key_name\": \"data\",\n",
    "        \"episodes_present\": len(parquet_eps),\n",
    "        \"episodes_missing\": len(all_eps - parquet_eps),\n",
    "        \"coverage_ratio\": (len(parquet_eps) / max(1, len(all_eps))),\n",
    "        \"missing_examples\": sorted(list(all_eps - parquet_eps))[:10],\n",
    "    })\n",
    "\n",
    "    # Video coverage per key\n",
    "    for vk in layout.video_keys:\n",
    "        files = layout.video_files.get(vk, [])\n",
    "        have = set()\n",
    "        for f in files:\n",
    "            ei = _parse_episode_index(f)\n",
    "            if ei is not None:\n",
    "                have.add(ei)\n",
    "\n",
    "        miss = sorted(list(all_eps - have))\n",
    "        rows.append({\n",
    "            \"key_type\": \"video\",\n",
    "            \"key_name\": vk,\n",
    "            \"episodes_present\": len(have),\n",
    "            \"episodes_missing\": len(miss),\n",
    "            \"coverage_ratio\": (len(have) / max(1, len(all_eps))),\n",
    "            \"missing_examples\": miss[:10],\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"key_type\", \"coverage_ratio\", \"key_name\"], ascending=[True, True, True])\n",
    "    return df\n",
    "\n",
    "def validate_layout(layout: DatasetLayout, info: dict | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Returns a structured validation report:\n",
    "      - summary: high-level counts\n",
    "      - coverage: per-key episode coverage table\n",
    "      - meta_counts_check: compare vs info.json (optional)\n",
    "    Raises on hard errors.\n",
    "    \"\"\"\n",
    "    # Hard errors\n",
    "    if not layout.root.exists():\n",
    "        raise FileNotFoundError(f\"DATA_ROOT not found: {layout.root}\")\n",
    "    if not layout.data_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing data dir: {layout.data_dir}\")\n",
    "    if not layout.videos_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing videos dir: {layout.videos_dir}\")\n",
    "    if len(layout.episode_indices) == 0:\n",
    "        raise RuntimeError(\"No episodes found (no episode_*.parquet under data/).\")\n",
    "\n",
    "    # Coverage table (your main ‚Äúsanity check‚Äù)\n",
    "    coverage = episode_coverage_report(layout)\n",
    "\n",
    "    # High-level summary\n",
    "    summary = {\n",
    "        \"root\": str(layout.root),\n",
    "        \"chunks\": layout.chunks,\n",
    "        \"episodes_found\": len(layout.episode_indices),\n",
    "        \"parquet_files_found\": len(layout.parquet_files),\n",
    "        \"video_keys_found\": len(layout.video_keys),\n",
    "        \"videos_found_total\": int(sum(len(v) for v in layout.video_files.values())),\n",
    "        \"meta_files_found\": sorted(layout.meta_files.keys()),\n",
    "    }\n",
    "\n",
    "    # Optional: compare against info.json\n",
    "    meta_counts_check = None\n",
    "    if info is not None:\n",
    "        meta_counts_check = {\n",
    "            \"info.total_episodes\": info.get(\"total_episodes\"),\n",
    "            \"info.total_videos\": info.get(\"total_videos\"),\n",
    "            \"episodes_found\": len(layout.episode_indices),\n",
    "            \"videos_found_total\": int(sum(len(v) for v in layout.video_files.values())),\n",
    "            \"match_total_episodes\": (info.get(\"total_episodes\") == len(layout.episode_indices)) if isinstance(info.get(\"total_episodes\"), int) else None,\n",
    "            \"match_total_videos\": (info.get(\"total_videos\") == int(sum(len(v) for v in layout.video_files.values()))) if isinstance(info.get(\"total_videos\"), int) else None,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"coverage\": coverage,\n",
    "        \"meta_counts_check\": meta_counts_check,\n",
    "    }\n",
    "\n",
    "report = validate_layout(layout, info)\n",
    "print(\"‚úÖ Layout validated.\\n\")\n",
    "print(\"SUMMARY:\")\n",
    "for k, v in report[\"summary\"].items():\n",
    "    print(f\"  ‚Ä¢ {k}: {v}\")\n",
    "\n",
    "print(\"\\nCOVERAGE (per key):\")\n",
    "display(report[\"coverage\"].sort_values([\"key_type\",\"key_name\"]))\n",
    "\n",
    "if report[\"meta_counts_check\"] is not None:\n",
    "    print(\"\\nINFO.JSON COUNT CHECK:\")\n",
    "    for k, v in report[\"meta_counts_check\"].items():\n",
    "        print(f\"  ‚Ä¢ {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab9e92-5ec4-4658-8fb8-635b9131d445",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5699cd2c-d487-482f-accc-4f7403fc2bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded meta:\n",
      "  ‚Ä¢ info.json: dict with 13 keys\n",
      "  ‚Ä¢ modality.json: dict with 4 keys\n",
      "  ‚Ä¢ tasks.jsonl: 2 lines sampled\n",
      "  ‚Ä¢ episodes.jsonl: 5 lines sampled\n",
      "  ‚Ä¢ stats.json: dict with 3 keys\n",
      "  ‚Ä¢ relative_stats.json: dict with 1 keys\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_json(path: Path) -> dict:\n",
    "    return json.loads(path.read_text())\n",
    "\n",
    "def read_jsonl(path: Path, max_lines: int | None = None) -> list[dict]:\n",
    "    rows = []\n",
    "    with path.open() as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_lines is not None and i >= max_lines:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "meta = {}\n",
    "for name in [\"info.json\", \"modality.json\", \"tasks.jsonl\", \"episodes.jsonl\", \"stats.json\", \"relative_stats.json\"]:\n",
    "    p = layout.meta_files.get(name)\n",
    "    if p and p.exists():\n",
    "        if name.endswith(\".json\"):\n",
    "            meta[name] = read_json(p)\n",
    "        elif name.endswith(\".jsonl\"):\n",
    "            # just sample for schema preview\n",
    "            meta[name] = read_jsonl(p, max_lines=50)\n",
    "\n",
    "info = meta.get(\"info.json\")\n",
    "modality = meta.get(\"modality.json\")\n",
    "tasks_sample = meta.get(\"tasks.jsonl\")   # list[dict] sample\n",
    "episodes_sample = meta.get(\"episodes.jsonl\")  # list[dict] sample\n",
    "\n",
    "print(\"Loaded meta:\")\n",
    "for k in meta.keys():\n",
    "    v = meta[k]\n",
    "    if isinstance(v, list):\n",
    "        print(f\"  ‚Ä¢ {k}: {len(v)} lines sampled\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ {k}: dict with {len(v)} keys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ccb06d-290e-45be-b20d-8079ba7c1924",
   "metadata": {},
   "source": [
    "## Feature Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b0f714-7aac-45db-817b-04be89e7a693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>dtype</th>\n",
       "      <th>shape</th>\n",
       "      <th>names</th>\n",
       "      <th>video.codec</th>\n",
       "      <th>video.fps</th>\n",
       "      <th>video.height</th>\n",
       "      <th>video.width</th>\n",
       "      <th>storage_hint</th>\n",
       "      <th>storage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>episode_index</td>\n",
       "      <td>int64</td>\n",
       "      <td>[1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>index(parquet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame_index</td>\n",
       "      <td>int64</td>\n",
       "      <td>[1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>index(parquet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>index</td>\n",
       "      <td>int64</td>\n",
       "      <td>[1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>index(parquet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>task_index</td>\n",
       "      <td>int64</td>\n",
       "      <td>[1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>index(parquet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>float32</td>\n",
       "      <td>[1]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>index(parquet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>action</td>\n",
       "      <td>float32</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[shoulder_pan.pos, shoulder_lift.pos, elbow_fl...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>observation.state</td>\n",
       "      <td>float32</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[shoulder_pan.pos, shoulder_lift.pos, elbow_fl...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parquet</td>\n",
       "      <td>parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>observation.images.front</td>\n",
       "      <td>video</td>\n",
       "      <td>[480, 640, 3]</td>\n",
       "      <td>[height, width, channels]</td>\n",
       "      <td>av1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>video</td>\n",
       "      <td>video(mp4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>observation.images.wrist</td>\n",
       "      <td>video</td>\n",
       "      <td>[480, 640, 3]</td>\n",
       "      <td>[height, width, channels]</td>\n",
       "      <td>av1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>video</td>\n",
       "      <td>video(mp4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature    dtype          shape  \\\n",
       "0             episode_index    int64            [1]   \n",
       "1               frame_index    int64            [1]   \n",
       "2                     index    int64            [1]   \n",
       "3                task_index    int64            [1]   \n",
       "4                 timestamp  float32            [1]   \n",
       "5                    action  float32            [6]   \n",
       "6         observation.state  float32            [6]   \n",
       "7  observation.images.front    video  [480, 640, 3]   \n",
       "8  observation.images.wrist    video  [480, 640, 3]   \n",
       "\n",
       "                                               names video.codec  video.fps  \\\n",
       "0                                               None        None        NaN   \n",
       "1                                               None        None        NaN   \n",
       "2                                               None        None        NaN   \n",
       "3                                               None        None        NaN   \n",
       "4                                               None        None        NaN   \n",
       "5  [shoulder_pan.pos, shoulder_lift.pos, elbow_fl...        None        NaN   \n",
       "6  [shoulder_pan.pos, shoulder_lift.pos, elbow_fl...        None        NaN   \n",
       "7                          [height, width, channels]         av1       30.0   \n",
       "8                          [height, width, channels]         av1       30.0   \n",
       "\n",
       "   video.height  video.width storage_hint         storage  \n",
       "0           NaN          NaN      parquet  index(parquet)  \n",
       "1           NaN          NaN      parquet  index(parquet)  \n",
       "2           NaN          NaN      parquet  index(parquet)  \n",
       "3           NaN          NaN      parquet  index(parquet)  \n",
       "4           NaN          NaN      parquet  index(parquet)  \n",
       "5           NaN          NaN      parquet         parquet  \n",
       "6           NaN          NaN      parquet         parquet  \n",
       "7         480.0        640.0        video      video(mp4)  \n",
       "8         480.0        640.0        video      video(mp4)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_feature_table(info: dict) -> pd.DataFrame:\n",
    "    feats = info.get(\"features\", {})\n",
    "    rows = []\n",
    "    for k, v in feats.items():\n",
    "        rows.append({\n",
    "            \"feature\": k,\n",
    "            \"dtype\": v.get(\"dtype\"),\n",
    "            \"shape\": v.get(\"shape\"),\n",
    "            \"names\": v.get(\"names\"),\n",
    "            # video extra info if present\n",
    "            \"video.codec\": (v.get(\"info\") or {}).get(\"video.codec\"),\n",
    "            \"video.fps\": (v.get(\"info\") or {}).get(\"video.fps\"),\n",
    "            \"video.height\": (v.get(\"info\") or {}).get(\"video.height\"),\n",
    "            \"video.width\": (v.get(\"info\") or {}).get(\"video.width\"),\n",
    "            \"storage_hint\": \"video\" if v.get(\"dtype\") == \"video\" else \"parquet\",\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Heuristic storage classification\n",
    "    def classify_storage(row):\n",
    "        f = row[\"feature\"]\n",
    "        if row[\"dtype\"] == \"video\" or str(f).startswith(\"observation.images\"):\n",
    "            return \"video(mp4)\"\n",
    "        if f in [\"index\", \"episode_index\", \"frame_index\", \"task_index\", \"timestamp\"]:\n",
    "            return \"index(parquet)\"\n",
    "        return \"parquet\"\n",
    "\n",
    "    df[\"storage\"] = df.apply(classify_storage, axis=1)\n",
    "    df = df.sort_values([\"storage\", \"feature\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "feature_df = build_feature_table(info)\n",
    "display(feature_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6848d8fe-958d-4f86-a896-325a409e15dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>logical_key</th>\n",
       "      <th>original_key</th>\n",
       "      <th>mapping_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>gripper</td>\n",
       "      <td>None</td>\n",
       "      <td>{'start': 5, 'end': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action</td>\n",
       "      <td>single_arm</td>\n",
       "      <td>None</td>\n",
       "      <td>{'start': 0, 'end': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>human.task_description</td>\n",
       "      <td>task_index</td>\n",
       "      <td>{'original_key': 'task_index'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>gripper</td>\n",
       "      <td>None</td>\n",
       "      <td>{'start': 5, 'end': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state</td>\n",
       "      <td>single_arm</td>\n",
       "      <td>None</td>\n",
       "      <td>{'start': 0, 'end': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video</td>\n",
       "      <td>front</td>\n",
       "      <td>observation.images.front</td>\n",
       "      <td>{'original_key': 'observation.images.front'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video</td>\n",
       "      <td>wrist</td>\n",
       "      <td>observation.images.wrist</td>\n",
       "      <td>{'original_key': 'observation.images.wrist'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     modality             logical_key              original_key  \\\n",
       "0      action                 gripper                      None   \n",
       "1      action              single_arm                      None   \n",
       "2  annotation  human.task_description                task_index   \n",
       "3       state                 gripper                      None   \n",
       "4       state              single_arm                      None   \n",
       "5       video                   front  observation.images.front   \n",
       "6       video                   wrist  observation.images.wrist   \n",
       "\n",
       "                                    mapping_raw  \n",
       "0                        {'start': 5, 'end': 6}  \n",
       "1                        {'start': 0, 'end': 5}  \n",
       "2                {'original_key': 'task_index'}  \n",
       "3                        {'start': 5, 'end': 6}  \n",
       "4                        {'start': 0, 'end': 5}  \n",
       "5  {'original_key': 'observation.images.front'}  \n",
       "6  {'original_key': 'observation.images.wrist'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_modality_table(modality: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for mod_name, mod_spec in modality.items():\n",
    "        # mod_spec usually: { logical_name: { original_key: ... } } OR nested structures\n",
    "        if isinstance(mod_spec, dict):\n",
    "            for logical_key, mapping in mod_spec.items():\n",
    "                if isinstance(mapping, dict):\n",
    "                    rows.append({\n",
    "                        \"modality\": mod_name,\n",
    "                        \"logical_key\": logical_key,\n",
    "                        \"original_key\": mapping.get(\"original_key\"),\n",
    "                        \"mapping_raw\": mapping,\n",
    "                    })\n",
    "                else:\n",
    "                    rows.append({\n",
    "                        \"modality\": mod_name,\n",
    "                        \"logical_key\": logical_key,\n",
    "                        \"original_key\": None,\n",
    "                        \"mapping_raw\": mapping,\n",
    "                    })\n",
    "        else:\n",
    "            rows.append({\n",
    "                \"modality\": mod_name,\n",
    "                \"logical_key\": None,\n",
    "                \"original_key\": None,\n",
    "                \"mapping_raw\": mod_spec,\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"modality\", \"logical_key\"]).reset_index(drop=True)\n",
    "\n",
    "modality_df = build_modality_table(modality)\n",
    "display(modality_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa442ca-a879-49b2-b1eb-81729d17ec68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>logical_key</th>\n",
       "      <th>original_key</th>\n",
       "      <th>source_storage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>gripper</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action</td>\n",
       "      <td>single_arm</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>human.task_description</td>\n",
       "      <td>task_index</td>\n",
       "      <td>index(parquet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>gripper</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state</td>\n",
       "      <td>single_arm</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video</td>\n",
       "      <td>front</td>\n",
       "      <td>observation.images.front</td>\n",
       "      <td>video(mp4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video</td>\n",
       "      <td>wrist</td>\n",
       "      <td>observation.images.wrist</td>\n",
       "      <td>video(mp4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     modality             logical_key              original_key  \\\n",
       "0      action                 gripper                      None   \n",
       "1      action              single_arm                      None   \n",
       "2  annotation  human.task_description                task_index   \n",
       "3       state                 gripper                      None   \n",
       "4       state              single_arm                      None   \n",
       "5       video                   front  observation.images.front   \n",
       "6       video                   wrist  observation.images.wrist   \n",
       "\n",
       "   source_storage  \n",
       "0         unknown  \n",
       "1         unknown  \n",
       "2  index(parquet)  \n",
       "3         unknown  \n",
       "4         unknown  \n",
       "5      video(mp4)  \n",
       "6      video(mp4)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build quick lookup from feature table\n",
    "feature_storage = dict(zip(feature_df[\"feature\"], feature_df[\"storage\"]))\n",
    "\n",
    "def infer_source(original_key: str | None) -> str:\n",
    "    if original_key is None:\n",
    "        return \"unknown\"\n",
    "    return feature_storage.get(original_key, \"meta-derived (needs lookup)\")\n",
    "\n",
    "contract_df = modality_df.copy()\n",
    "contract_df[\"source_storage\"] = contract_df[\"original_key\"].apply(infer_source)\n",
    "\n",
    "# Some derived logical keys are not direct features but lookups from meta (task description, etc.)\n",
    "# Heuristic: if original_key exists but not in features, mark meta-derived.\n",
    "contract_df = contract_df.sort_values([\"modality\", \"source_storage\", \"logical_key\"]).reset_index(drop=True)\n",
    "\n",
    "display(contract_df[[\"modality\",\"logical_key\",\"original_key\",\"source_storage\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56edb49b-dc09-459c-91ad-394eadc7862e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tasks.jsonl</td>\n",
       "      <td>task_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tasks.jsonl</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file         key\n",
       "0  tasks.jsonl  task_index\n",
       "1  tasks.jsonl        task"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>episodes.jsonl</td>\n",
       "      <td>episode_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>episodes.jsonl</td>\n",
       "      <td>tasks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>episodes.jsonl</td>\n",
       "      <td>length</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file            key\n",
       "0  episodes.jsonl  episode_index\n",
       "1  episodes.jsonl          tasks\n",
       "2  episodes.jsonl         length"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def schema_preview(rows: list[dict], name: str, max_keys: int = 50) -> pd.DataFrame:\n",
    "    # union of keys across sampled rows\n",
    "    keys = []\n",
    "    seen = set()\n",
    "    for r in rows:\n",
    "        for k in r.keys():\n",
    "            if k not in seen:\n",
    "                seen.add(k)\n",
    "                keys.append(k)\n",
    "    keys = keys[:max_keys]\n",
    "    return pd.DataFrame({\"file\": name, \"key\": keys})\n",
    "\n",
    "if tasks_sample:\n",
    "    display(schema_preview(tasks_sample, \"tasks.jsonl\"))\n",
    "if episodes_sample:\n",
    "    display(schema_preview(episodes_sample, \"episodes.jsonl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019143d-f8f0-4d94-ae25-aa99edd27eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lerobot-uv)",
   "language": "python",
   "name": "lerobot-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
